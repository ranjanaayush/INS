{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a38283f-754e-410e-99ee-c22a995c216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def simulate_central_scenario(seed=1234):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # --- Policy Data ---\n",
    "    date_range = pd.date_range(start=\"2016-01-01\", end=\"2017-12-31\", freq=\"D\")\n",
    "    dt_policydates = pd.DataFrame({'date_UW': date_range})\n",
    "\n",
    "    policycount = np.random.poisson(700, size=len(dt_policydates))\n",
    "    dt_policydates['policycount'] = policycount\n",
    "    dt_policydates['date_lapse'] = dt_policydates['date_UW'].apply(lambda d: d + relativedelta(years=1))\n",
    "    dt_policydates['expodays'] = (dt_policydates['date_lapse'] - dt_policydates['date_UW']).dt.days\n",
    "    dt_policydates['pol_prefix'] = dt_policydates['date_UW'].dt.year * 10000 + \\\n",
    "                                   dt_policydates['date_UW'].dt.month * 100 + \\\n",
    "                                   dt_policydates['date_UW'].dt.day\n",
    "\n",
    "    # Cover breakdowns\n",
    "    dt_policydates['Cover_B'] = (dt_policydates['policycount'] * 0.25).round().astype(int)\n",
    "    dt_policydates['Cover_BO'] = (dt_policydates['policycount'] * 0.45).round().astype(int)\n",
    "    dt_policydates['Cover_BOT'] = dt_policydates['policycount'] - dt_policydates['Cover_B'] - dt_policydates['Cover_BO']\n",
    "\n",
    "    # Repeat by policy count\n",
    "    dt_policy = dt_policydates.loc[dt_policydates.index.repeat(dt_policydates['policycount'])].copy()\n",
    "    dt_policy['pol_seq'] = dt_policy.groupby('pol_prefix').cumcount() + 1\n",
    "    dt_policy['pol_number'] = (dt_policy['pol_prefix'] * 10000 + dt_policy['pol_seq']).astype(str)\n",
    "\n",
    "    # Assign cover type\n",
    "    dt_policy['Cover'] = 'BO'\n",
    "    dt_policy['tmp_index'] = dt_policy.groupby('pol_prefix').cumcount()\n",
    "\n",
    "    dt_policy.loc[dt_policy['tmp_index'] < (dt_policy['policycount'] - dt_policy['Cover_BO']), 'Cover'] = 'BOT'\n",
    "    dt_policy.loc[dt_policy['tmp_index'] < dt_policy['Cover_B'], 'Cover'] = 'B'\n",
    "\n",
    "    # Clean up\n",
    "    dt_policy.drop(columns=['pol_prefix', 'policycount', 'pol_seq', 'Cover_B', 'Cover_BO', 'Cover_BOT', 'tmp_index'], inplace=True)\n",
    "\n",
    "    # Assign Brand and Base_Price\n",
    "    brand_cycle = np.tile(np.repeat([1, 2, 3, 4], [9, 6, 3, 2]), int(np.ceil(len(dt_policy)/20)))[:len(dt_policy)]\n",
    "    base_price_map = {1: 600, 2: 550, 3: 300, 4: 150}\n",
    "    dt_policy['Brand'] = brand_cycle\n",
    "    dt_policy['Base_Price'] = [base_price_map[b] for b in dt_policy['Brand']]\n",
    "\n",
    "    model_cycle = np.repeat([3, 2, 1, 0], [10, 7, 2, 1])\n",
    "    model_mult_map = {3: 1.15**3, 2: 1.15**2, 1: 1.15**1, 0: 1.0}\n",
    "    \n",
    "    model_list = []\n",
    "    model_mult_list = []\n",
    "    for brand in dt_policy['Brand'].unique():\n",
    "        brand_mask = dt_policy['Brand'] == brand\n",
    "        count = brand_mask.sum()\n",
    "        repeated_models = np.tile(model_cycle, int(np.ceil(count / len(model_cycle))))[:count]\n",
    "        model_list.extend(repeated_models)\n",
    "        model_mult_list.extend([model_mult_map[m] for m in repeated_models])\n",
    "    \n",
    "    dt_policy['Model'] = model_list\n",
    "    dt_policy['Model_mult'] = model_mult_list\n",
    "    dt_policy['Price'] = np.ceil(dt_policy['Base_Price'] * dt_policy['Model_mult']).astype(int)\n",
    "\n",
    "    dt_policy = dt_policy[['pol_number', 'date_UW', 'date_lapse', 'Cover', 'Brand', 'Model', 'Price']]\n",
    "\n",
    "    # --- Claims Data ---\n",
    "    dt_policy = dt_policy.reset_index(drop=True)\n",
    "\n",
    "    total_policies = len(dt_policy)\n",
    "    claim_indices = np.random.choice(dt_policy.index, size=int(0.15 * total_policies), replace=False)\n",
    "\n",
    "    print(f\"Length of claim_indices: {len(claim_indices)}\")\n",
    "    print(f\"Length of pol_number array: {len(dt_policy.loc[claim_indices, 'pol_number'].values)}\")\n",
    "\n",
    "    dt_claim = pd.DataFrame({\n",
    "        'pol_number': dt_policy.loc[claim_indices, 'pol_number'].values,\n",
    "        'claim_type': ['B'] * len(claim_indices),\n",
    "        'claim_count': [1] * len(claim_indices),\n",
    "        'claim_sev': np.random.beta(2, 5, size=len(claim_indices))\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    cov = dt_policy.index[dt_policy['Cover'] != 'B']\n",
    "    claim_indices = np.random.choice(cov, size=int(0.05 * len(cov)), replace=False)\n",
    "    oxidation_claims = pd.DataFrame({\n",
    "        'pol_number': dt_policy.loc[claim_indices, 'pol_number'].values,\n",
    "        'claim_type': 'O',\n",
    "        'claim_count': 1,\n",
    "        'claim_sev': np.random.beta(5, 3, size=len(claim_indices))\n",
    "    })\n",
    "    dt_claim = pd.concat([dt_claim, oxidation_claims], ignore_index=True)\n",
    "\n",
    "    for model in range(4):\n",
    "        model_cov = dt_policy[(dt_policy['Cover'] == 'BOT') & (dt_policy['Model'] == model)].index\n",
    "        claim_count = int(0.05 * (1 + model) * len(model_cov))\n",
    "        if claim_count > 0:\n",
    "            theft_claims = pd.DataFrame({\n",
    "                'pol_number': dt_policy.loc[np.random.choice(model_cov, size=claim_count, replace=False), 'pol_number'].values,\n",
    "                'claim_type': 'T',\n",
    "                'claim_count': 1,\n",
    "                'claim_sev': np.random.beta(5, 0.5, size=claim_count)\n",
    "            })\n",
    "            dt_claim = pd.concat([dt_claim, theft_claims], ignore_index=True)\n",
    "\n",
    "    dt_claim = dt_claim.merge(dt_policy[['pol_number', 'date_UW', 'Price', 'Brand']], on='pol_number', how='left')\n",
    "    dt_claim['date_lapse'] = dt_claim['date_UW'] + pd.to_timedelta(365, unit='D')\n",
    "    dt_claim['expodays'] = (dt_claim['date_lapse'] - dt_claim['date_UW']).dt.days\n",
    "    dt_claim['occ_delay_days'] = (dt_claim['expodays'] * np.random.uniform(size=len(dt_claim))).astype(int)\n",
    "    dt_claim['delay_report'] = np.floor(365 * np.random.beta(0.4, 10, size=len(dt_claim))).astype(int)\n",
    "    dt_claim['delay_pay'] = np.floor(10 + 40 * np.random.beta(7, 7, size=len(dt_claim))).astype(int)\n",
    "\n",
    "    dt_claim['date_occur'] = dt_claim['date_UW'] + pd.to_timedelta(dt_claim['occ_delay_days'], unit='D')\n",
    "    dt_claim['date_report'] = dt_claim['date_occur'] + pd.to_timedelta(dt_claim['delay_report'], unit='D')\n",
    "    dt_claim['date_pay'] = dt_claim['date_report'] + pd.to_timedelta(dt_claim['delay_pay'], unit='D')\n",
    "    dt_claim['claim_cost'] = np.round(dt_claim['Price'] * dt_claim['claim_sev']).astype(int)\n",
    "\n",
    "    dt_claim['clm_prefix'] = dt_claim['date_report'].dt.year * 10000 + \\\n",
    "                             dt_claim['date_report'].dt.month * 100 + \\\n",
    "                             dt_claim['date_report'].dt.day\n",
    "    dt_claim['clm_seq'] = dt_claim.groupby('clm_prefix').cumcount() + 1\n",
    "    dt_claim['clm_number'] = (dt_claim['clm_prefix'] * 10000 + dt_claim['clm_seq']).astype(str)\n",
    "\n",
    "    dt_claim['polclm_seq'] = dt_claim.groupby('pol_number').cumcount() + 1\n",
    "    dt_claim = dt_claim[dt_claim['polclm_seq'] == 1]\n",
    "\n",
    "    dt_claim = dt_claim[['clm_number', 'pol_number', 'claim_type', 'claim_count', 'claim_sev',\n",
    "                         'date_occur', 'date_report', 'date_pay', 'claim_cost']]\n",
    "\n",
    "    return {\n",
    "        'dt_policy': dt_policy.reset_index(drop=True),\n",
    "        'dt_claim': dt_claim.reset_index(drop=True)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05106b3f-7507-42cd-a23e-7c7edf70d4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2e1e15d-fcbc-4b90-9394-b69ca4cab82d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'claim_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of claim_indices: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(claim_indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of pol_number array: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dt_policy\u001b[38;5;241m.\u001b[39mloc[claim_indices,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpol_number\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of claim_type list: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(claim_indices))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'claim_indices' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Length of claim_indices: {len(claim_indices)}\")\n",
    "print(f\"Length of pol_number array: {len(dt_policy.loc[claim_indices, 'pol_number'].values)}\")\n",
    "print(f\"Length of claim_type list: {len(['B'] * len(claim_indices))}\")\n",
    "print(f\"Length of claim_count list: {len([1] * len(claim_indices))}\")\n",
    "print(f\"Length of claim_sev array: {len(np.random.beta(2, 5, size=len(claim_indices)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526eb2b4-46b9-4bf1-a5d3-01a92e680b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7928abee-b119-4800-b6a6-0a26ff1794e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d3090-1798-45d4-9e53-4c3377fb6d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6696e0fe-3fbb-4607-8b43-459ea0146036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def join_policy_claim(dt_PhoneData,\n",
    "                      date_pol_start=\"date_UW\",\n",
    "                      date_pol_end=\"date_lapse\",\n",
    "                      date_occur=\"date_occur\"):\n",
    "    # Extract policy and claim data\n",
    "    dt_policy = dt_PhoneData['dt_policy'].copy()\n",
    "    dt_claim = dt_PhoneData['dt_claim'].copy()\n",
    "\n",
    "    # Rename policy columns to generic names for matching\n",
    "    dt_policy = dt_policy.rename(columns={date_pol_start: \"date_pol_start\", date_pol_end: \"date_pol_end\"})\n",
    "\n",
    "    # Floor dates to the second\n",
    "    dt_policy[\"date_pol_start\"] = pd.to_datetime(dt_policy[\"date_pol_start\"]).dt.floor(\"S\")\n",
    "    dt_policy[\"date_pol_end\"] = pd.to_datetime(dt_policy[\"date_pol_end\"]).dt.floor(\"S\") - pd.Timedelta(seconds=1)\n",
    "\n",
    "    dt_claim[\"date_occur\"] = pd.to_datetime(dt_claim[date_occur]).dt.floor(\"S\")\n",
    "    dt_claim[\"date_occur_end\"] = dt_claim[\"date_occur\"]\n",
    "    dt_claim[\"date_report\"] = pd.to_datetime(dt_claim[\"date_report\"]).dt.floor(\"S\")\n",
    "    dt_claim[\"date_pay\"] = pd.to_datetime(dt_claim[\"date_pay\"]).dt.floor(\"S\")\n",
    "\n",
    "    # Create policy period interval and occurrence interval\n",
    "    dt_policy[\"policy_interval\"] = pd.IntervalIndex.from_arrays(dt_policy[\"date_pol_start\"],\n",
    "                                                                dt_policy[\"date_pol_end\"],\n",
    "                                                                closed='both')\n",
    "    dt_claim[\"occur_interval\"] = pd.IntervalIndex.from_arrays(dt_claim[\"date_occur\"],\n",
    "                                                              dt_claim[\"date_occur_end\"],\n",
    "                                                              closed='both')\n",
    "\n",
    "    # Perform overlap join using row-wise comparison\n",
    "    dt_claim = dt_claim.set_index('pol_number')\n",
    "    dt_policy = dt_policy.set_index('pol_number')\n",
    "\n",
    "    def match_claims(row):\n",
    "        if row.name not in dt_claim.index:\n",
    "            return pd.Series([np.nan]*len(dt_claim.columns), index=dt_claim.columns)\n",
    "        possible_claims = dt_claim.loc[[row.name]]\n",
    "        matched = possible_claims[possible_claims[\"occur_interval\"].overlaps(row[\"policy_interval\"])]\n",
    "        return matched.iloc[0] if not matched.empty else pd.Series([np.nan]*len(dt_claim.columns), index=dt_claim.columns)\n",
    "\n",
    "    claim_data = dt_policy.apply(match_claims, axis=1)\n",
    "\n",
    "    # Combine policy and claim\n",
    "    dt_polclaim = dt_policy.reset_index().join(claim_data.reset_index(drop=True))\n",
    "\n",
    "    # Fill date NAs with distant future for safety\n",
    "    date_fields = [col for col in dt_polclaim.columns if \"date\" in col]\n",
    "    for field in date_fields:\n",
    "        dt_polclaim[field] = dt_polclaim[field].fillna(pd.to_datetime(\"2199-12-31 23:59:59\"))\n",
    "\n",
    "    # Set claim count/severity/cost NAs to zero\n",
    "    for field in [\"claim_count\", \"claim_sev\", \"claim_cost\"]:\n",
    "        if field in dt_polclaim.columns:\n",
    "            dt_polclaim[field] = dt_polclaim[field].fillna(0)\n",
    "\n",
    "    # Calculate exposure days\n",
    "    dt_polclaim[\"ExpoDays\"] = np.ceil(\n",
    "        (dt_polclaim[\"date_pol_end\"] - dt_polclaim[\"date_pol_start\"]) / np.timedelta64(1, 'D')\n",
    "    ).astype(int)\n",
    "\n",
    "    # Remove zero-exposure entries\n",
    "    dt_polclaim = dt_polclaim[dt_polclaim[\"ExpoDays\"] > 0].reset_index(drop=True)\n",
    "\n",
    "    return dt_polclaim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649143e2-7490-4282-95ee-84918f3a355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def time_slice_polclaim(dt_polclaim, lst_Date_slice=None):\n",
    "    \"\"\"\n",
    "    Time slice Policy & Claims data.\n",
    "    Adds one column per slice named 'P_t_YYYYMMDD', showing claim cost if paid by that date, else 0.\n",
    "    \"\"\"\n",
    "\n",
    "    # Default time slices: every 30 days from Jan 1, 2016 to June 30, 2019\n",
    "    if lst_Date_slice is None:\n",
    "        lst_Date_slice = pd.date_range(start=\"2016-01-01\", end=\"2019-06-30\", freq=\"30D\").floor(\"S\")\n",
    "\n",
    "    dt_polclaim = dt_polclaim.copy()\n",
    "\n",
    "    for date_slice in lst_Date_slice:\n",
    "        col_name = f'P_t_{date_slice.strftime(\"%Y%m%d\")}'\n",
    "        dt_polclaim[col_name] = np.where(\n",
    "            dt_polclaim['date_pay'] <= date_slice,\n",
    "            dt_polclaim['claim_cost'],\n",
    "            0\n",
    "        )\n",
    "\n",
    "    # Sort by policy number\n",
    "    dt_polclaim = dt_polclaim.sort_values(by='pol_number').reset_index(drop=True)\n",
    "\n",
    "    return dt_polclaim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be1636a-e9c3-4111-ad5d-fe1fd3fca32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBNS_Train_ijk(dt_policy_claim, date_i, j_dev_period, k, reserving_dates, model_vars):\n",
    "    date_i = pd.to_datetime(date_i)\n",
    "    \n",
    "    date_k = reserving_dates[reserving_dates.index(date_i) - k + 1]\n",
    "    date_j = reserving_dates[reserving_dates.index(date_k) - j_dev_period]\n",
    "    date_lookup = reserving_dates[reserving_dates.index(date_i) - j_dev_period - k + 1]\n",
    "    \n",
    "    target_lookup = reserving_dates[reserving_dates.index(date_i) - k]\n",
    "    target_lookup_next = reserving_dates[reserving_dates.index(date_i) - k + 1]\n",
    "    \n",
    "    # Filter: reported but not paid as at date_lookup\n",
    "    df = dt_policy_claim[\n",
    "        (dt_policy_claim['date_report'] <= date_lookup) &\n",
    "        (dt_policy_claim['date_pay'] > date_lookup)\n",
    "    ].copy()\n",
    "\n",
    "    df['date_lookup'] = date_lookup\n",
    "    df['delay_train'] = (date_lookup - df['date_pol_start']).dt.days\n",
    "    df['j'] = j_dev_period\n",
    "    df['k'] = k\n",
    "    df['target'] = np.where(\n",
    "        df['date_pay'] <= target_lookup, 0,\n",
    "        np.where(df['date_pay'] <= target_lookup_next, df['claim_cost'], 0)\n",
    "    )\n",
    "\n",
    "    return df[model_vars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "027780c2-e3d2-4de1-a280-92cd6cb4b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBNS_Test_ijk(dt_policy_claim, date_i, j_dev_period, k, reserving_dates, model_vars):\n",
    "    date_i = pd.to_datetime(date_i)\n",
    "\n",
    "    date_lookup = reserving_dates[reserving_dates.index(date_i)]\n",
    "    target_lookup = reserving_dates[reserving_dates.index(date_i) + j_dev_period - 1]\n",
    "    target_lookup_next = reserving_dates[reserving_dates.index(date_i) + j_dev_period]\n",
    "\n",
    "    # Filter: reported but not paid as at date_lookup\n",
    "    df = dt_policy_claim[\n",
    "        (dt_policy_claim['date_report'] <= date_lookup) &\n",
    "        (date_lookup < dt_policy_claim['date_pay'])\n",
    "    ].copy()\n",
    "\n",
    "    df['date_lookup'] = date_lookup\n",
    "    df['delay_train'] = (date_lookup - df['date_pol_start']).dt.days\n",
    "    df['j'] = j_dev_period\n",
    "    df['k'] = k\n",
    "    df['target'] = np.where(\n",
    "        df['date_pay'] <= target_lookup, 0,\n",
    "        np.where(df['date_pay'] <= target_lookup_next, df['claim_cost'], 0)\n",
    "    )\n",
    "\n",
    "    return df[model_vars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36a6a9b0-9060-490e-8b28-9eeb3388b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBNS_Train(dt_policy_claim, date_i, i, k_max, reserving_dates, model_vars):\n",
    "    dt_train = []\n",
    "\n",
    "    for k in range(1, k_max + 1):\n",
    "        for j in range(1, i - k + 2):  # inclusive loop in R is 1:(i - k + 1)\n",
    "            df_part = RBNS_Train_ijk(dt_policy_claim, date_i, j, k, reserving_dates, model_vars)\n",
    "            dt_train.append(df_part)\n",
    "\n",
    "    return pd.concat(dt_train, ignore_index=True) if dt_train else pd.DataFrame(columns=model_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a74022cb-7bbe-41f5-b380-aa31812c86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBNS_Test(dt_policy_claim, date_i, delta, k_max, reserving_dates, model_vars):\n",
    "    dt_test = []\n",
    "\n",
    "    for k in range(1, k_max + 1):\n",
    "        for j in range(1, delta - k + 2):  # inclusive loop in R is 1:(delta - k + 1)\n",
    "            df_part = RBNS_Test_ijk(dt_policy_claim, date_i, j, k, reserving_dates, model_vars)\n",
    "            dt_test.append(df_part)\n",
    "\n",
    "    return pd.concat(dt_test, ignore_index=True) if dt_test else pd.DataFrame(columns=model_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf37d18f-4402-4deb-a725-4c152483dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IBNR_Freq_Train_ijk(dt_policy_claim, date_i, j_dev_period, k, reserving_dates, model_vars, verbose=False):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    date_i = pd.to_datetime(date_i)\n",
    "    \n",
    "    idx_i = reserving_dates.index(date_i)\n",
    "    date_k = reserving_dates[idx_i - k + 1]\n",
    "    date_j = reserving_dates[reserving_dates.index(date_k) - j_dev_period]\n",
    "    date_lookup = reserving_dates[idx_i - j_dev_period - k + 1]\n",
    "    target_lookup = reserving_dates[idx_i - k]\n",
    "    target_lookup_next = reserving_dates[idx_i - k + 1]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Valn date {date_i.date()}, j = {j_dev_period}, k = {k}\")\n",
    "\n",
    "    # Define IBNR population: policies not yet reported as of date_lookup\n",
    "    df = dt_policy_claim[\n",
    "        (dt_policy_claim['date_pol_start'] < date_lookup) &\n",
    "        (dt_policy_claim['date_report'] > date_lookup)\n",
    "    ].copy()\n",
    "\n",
    "    # Add engineered features\n",
    "    df['date_lookup'] = date_lookup\n",
    "    df['delay_train'] = (df['date_lookup'] - df['date_pol_start']).dt.days\n",
    "\n",
    "    df['j'] = j_dev_period\n",
    "    df['k'] = k\n",
    "\n",
    "    # Compute exposure in years\n",
    "    min_date = pd.to_datetime(date_i).floor('s')\n",
    "    df['exposure'] = ((np.minimum(df['date_pol_end'], min_date) - df['date_pol_start']).dt.total_seconds() / (365 * 24 * 60 * 60)).round(3)\n",
    "\n",
    "    # Target is 1 if claim occurred and was paid in the target window\n",
    "    df['target'] = np.where(\n",
    "        (df['date_pay'] >= target_lookup) &\n",
    "        (df['date_pay'] < target_lookup_next) &\n",
    "        (df['date_occur'] <= date_lookup),\n",
    "        1, 0\n",
    "    )\n",
    "\n",
    "    # Aggregate exposure across model vars excluding exposure\n",
    "    group_vars = [var for var in model_vars if var != 'exposure']\n",
    "    df_agg = df.groupby(group_vars, as_index=False)['exposure'].sum()\n",
    "\n",
    "    # Ensure all model_vars are present in the final dataframe\n",
    "    return df_agg[model_vars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75a3daf9-5e8b-4d6c-bafd-ec547d509b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IBNR_Loss_Train_ijk(dt_policy_claim, date_i, j_dev_period, k, reserving_dates, model_vars, verbose=False):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    date_i = pd.to_datetime(date_i)\n",
    "\n",
    "    idx_i = reserving_dates.index(date_i)\n",
    "    date_k = reserving_dates[idx_i - k + 1]\n",
    "    date_j = reserving_dates[reserving_dates.index(date_k) - j_dev_period]\n",
    "    date_lookup = reserving_dates[idx_i - j_dev_period - k + 1]\n",
    "    target_lookup = reserving_dates[idx_i - k]\n",
    "    target_lookup_next = reserving_dates[idx_i - k + 1]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Valn date {date_i.date()}, j = {j_dev_period}, k = {k}\")\n",
    "\n",
    "    df = dt_policy_claim[\n",
    "        (dt_policy_claim['date_report'] > date_lookup) &\n",
    "        (dt_policy_claim['date_occur'] < date_lookup) &\n",
    "        (dt_policy_claim['date_pay'] >= target_lookup) &\n",
    "        (dt_policy_claim['date_pay'] < target_lookup_next)\n",
    "    ].copy()\n",
    "\n",
    "    df['date_lookup'] = date_lookup\n",
    "    df['delay_train'] = (date_lookup - df['date_pol_start']).dt.days\n",
    "    df['j'] = j_dev_period\n",
    "    df['k'] = k\n",
    "    df['exposure'] = 1  # all claims treated equal\n",
    "\n",
    "    df['target'] = np.where(\n",
    "        (df['date_pay'] >= target_lookup) & (df['date_pay'] < target_lookup_next),\n",
    "        df['claim_cost'],\n",
    "        0\n",
    "    )\n",
    "\n",
    "    return df[model_vars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0b12fa1-ee45-4665-9c2b-1a82991c2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IBNR_Test_ijk(dt_policy_claim, date_i, j_dev_period, k, reserving_dates, model_vars, verbose=False):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    date_i = pd.to_datetime(date_i)\n",
    "\n",
    "    idx_i = reserving_dates.index(date_i)\n",
    "    date_lookup = reserving_dates[idx_i]\n",
    "    target_lookup = reserving_dates[idx_i + j_dev_period - 1]\n",
    "    target_lookup_next = reserving_dates[idx_i + j_dev_period]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Valn date {date_i.date()}, j = {j_dev_period}, k = {k}\")\n",
    "\n",
    "    df = dt_policy_claim[\n",
    "        (dt_policy_claim['date_pol_start'] <= date_lookup) &\n",
    "        (dt_policy_claim['date_report'] > date_lookup)\n",
    "    ].copy()\n",
    "\n",
    "    df['date_lookup'] = date_lookup\n",
    "    df['delay_train'] = (date_lookup - df['date_pol_start']).dt.days\n",
    "    df['j'] = j_dev_period\n",
    "    df['k'] = k\n",
    "\n",
    "    min_date = pd.to_datetime(date_i).floor('s')\n",
    "    df['exposure'] = ((np.minimum(df['date_pol_end'], min_date) - df['date_pol_start']).dt.total_seconds() / (365 * 24 * 60 * 60)).round(3)\n",
    "\n",
    "    df['target'] = np.where(\n",
    "        (df['date_pay'] >= target_lookup) &\n",
    "        (df['date_pay'] < target_lookup_next) &\n",
    "        (df['date_occur'] <= date_lookup),\n",
    "        df['claim_cost'],\n",
    "        0\n",
    "    )\n",
    "\n",
    "    group_vars = [var for var in model_vars if var != 'exposure']\n",
    "    df_agg = df.groupby(group_vars, as_index=False)['exposure'].sum()\n",
    "\n",
    "    return df_agg[model_vars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86129576-a57d-43e0-ba33-2c0d384fc44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IBNR_Train(dt_policy_claim, date_i, i, k, reserving_dates, model_vars, verbose=False):\n",
    "    dt_train_Freq = pd.DataFrame()\n",
    "    dt_train_Loss = pd.DataFrame()\n",
    "\n",
    "    for kk in range(1, k + 1):\n",
    "        for j in range(1, i - kk + 2):\n",
    "            df_freq = IBNR_Freq_Train_ijk(dt_policy_claim, date_i, j, kk, reserving_dates, model_vars, verbose)\n",
    "            df_loss = IBNR_Loss_Train_ijk(dt_policy_claim, date_i, j, kk, reserving_dates, model_vars, verbose)\n",
    "\n",
    "            dt_train_Freq = pd.concat([dt_train_Freq, df_freq], ignore_index=True)\n",
    "            dt_train_Loss = pd.concat([dt_train_Loss, df_loss], ignore_index=True)\n",
    "\n",
    "    return {'Freq': dt_train_Freq, 'Loss': dt_train_Loss}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a15515f6-db78-43d1-acff-324e3c14fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IBNR_Test(dt_policy_claim, date_i, delta, k, reserving_dates, model_vars, verbose=False):\n",
    "    dt_test = pd.DataFrame()\n",
    "\n",
    "    for kk in range(1, k + 1):\n",
    "        for j in range(1, delta - kk + 2):\n",
    "            df = IBNR_Test_ijk(dt_policy_claim, date_i, j, kk, reserving_dates, model_vars, verbose)\n",
    "            dt_test = pd.concat([dt_test, df], ignore_index=True)\n",
    "\n",
    "    return dt_test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
